<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples · CRRao.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://xKDR.github.io/CRRao.jl/examples/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">CRRao.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Examples</a><ul class="internal"><li><a class="tocitem" href="#Example-1:-Linear-Regression"><span>Example 1: Linear Regression</span></a></li><li><a class="tocitem" href="#Example-2:-Logistic-Regression"><span>Example 2: Logistic Regression</span></a></li><li><a class="tocitem" href="#Example-3:-Poisson-Regression"><span>Example 3: Poisson Regression</span></a></li><li><a class="tocitem" href="#Example-4:-Negative-Binomial-Regression"><span>Example 4: Negative Binomial Regression</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Examples</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/xKDR/CRRao.jl/blob/master/docs/src/examples.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h2 id="Example-1:-Linear-Regression"><a class="docs-heading-anchor" href="#Example-1:-Linear-Regression">Example 1: Linear Regression</a><a id="Example-1:-Linear-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1:-Linear-Regression" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using RDatasets, NLSolversBase, CRRao, Logging</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; Logging.disable_logging(Logging.Warn); CRRao.setprogress!(false)</code><code class="nohighlight hljs ansi" style="display:block;">false</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; df = dataset(&quot;datasets&quot;, &quot;mtcars&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">32×12 DataFrame
 Row │ Model              MPG      Cyl    Disp     HP     DRat     WT       QS ⋯
     │ String31           Float64  Int64  Float64  Int64  Float64  Float64  Fl ⋯
─────┼──────────────────────────────────────────────────────────────────────────
   1 │ Mazda RX4             21.0      6    160.0    110     3.9     2.62      ⋯
   2 │ Mazda RX4 Wag         21.0      6    160.0    110     3.9     2.875
   3 │ Datsun 710            22.8      4    108.0     93     3.85    2.32
   4 │ Hornet 4 Drive        21.4      6    258.0    110     3.08    3.215
   5 │ Hornet Sportabout     18.7      8    360.0    175     3.15    3.44      ⋯
   6 │ Valiant               18.1      6    225.0    105     2.76    3.46
   7 │ Duster 360            14.3      8    360.0    245     3.21    3.57
   8 │ Merc 240D             24.4      4    146.7     62     3.69    3.19
  ⋮  │         ⋮             ⋮       ⋮       ⋮       ⋮       ⋮        ⋮        ⋱
  26 │ Fiat X1-9             27.3      4     79.0     66     4.08    1.935     ⋯
  27 │ Porsche 914-2         26.0      4    120.3     91     4.43    2.14
  28 │ Lotus Europa          30.4      4     95.1    113     3.77    1.513
  29 │ Ford Pantera L        15.8      8    351.0    264     4.22    3.17
  30 │ Ferrari Dino          19.7      6    145.0    175     3.62    2.77      ⋯
  31 │ Maserati Bora         15.0      8    301.0    335     3.54    3.57
  32 │ Volvo 142E            21.4      4    121.0    109     4.11    2.78
                                                   5 columns and 17 rows omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1 = @fitmodel((MPG ~ HP + WT+Gear),df,LinearRegression())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_lm_Gauss_NIP_Optim(MPG ~ HP + WT + Gear, &quot;LinearReg&quot;, &quot;Gauss&quot;, &quot;NIP&quot;, &quot;Identity&quot;, &quot;Optimization&quot;, StatsModels.TableRegressionModel{GLM.LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}

MPG ~ 1 + HP + WT + Gear

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      t  Pr(&gt;|t|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  32.0137     4.63226      6.91    &lt;1e-06  22.5249     41.5024
HP           -0.0367861  0.00989146  -3.72    0.0009  -0.0570478  -0.0165243
WT           -3.19781    0.846546    -3.78    0.0008  -4.93188    -1.46374
Gear          1.01998    0.851408     1.20    0.2410  -0.72405     2.76401
────────────────────────────────────────────────────────────────────────────, ────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      t  Pr(&gt;|t|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  32.0137     4.63226      6.91    &lt;1e-06  22.5249     41.5024
HP           -0.0367861  0.00989146  -3.72    0.0009  -0.0570478  -0.0165243
WT           -3.19781    0.846546    -3.78    0.0008  -4.93188    -1.46374
Gear          1.01998    0.851408     1.20    0.2410  -0.72405     2.76401
────────────────────────────────────────────────────────────────────────────, -73.52638935960971, 157.05277871921942, 164.38145823321804, 0.8352309600685555, 0.8175771343616149, 2.5741691724978977, [23.668849952338704, 22.853408243206346, 25.253556140740866, 20.746171762311327, 17.63557054383011, 20.146638453886396, 14.644831040166551, 23.61182872351377, 22.525801204993858, 20.5684264750049  …  18.571211069285088, 13.781422171673466, 16.34045724109048, 27.477936821121038, 26.92271503957491, 28.118449005198737, 17.264981908248625, 21.818065399379666, 13.37404747719859, 23.193986311384343], [-2.6688499523387037, -1.8534082432063457, -2.453556140740865, 0.6538282376886713, 1.06442945616989, -2.046638453886395, -0.3448310401665502, 0.7881712764862279, 0.27419879500614286, -1.3684264750049024  …  -3.3712110692850885, -0.481422171673465, 2.8595427589095195, -0.17793682112103681, -0.9227150395749106, 2.281550994801261, -1.4649819082486246, -2.1180653993796668, 1.6259525228014091, -1.7939863113843444], [0.013342034282302684, 0.00688728266731234, 0.015495847517058797, 0.0014309089637600369, 0.004471979213924145, 0.014588985833724696, 0.0015401004198812064, 0.005826402580870707, 0.0003074315682457445, 0.007011803724485943  …  0.033303982249971296, 0.0020768256096929424, 0.02203970419212919, 0.0001378106083284689, 0.006862929526075293, 0.047038899451778936, 0.0381204513180911, 0.03540469459036285, 0.13715341355042346, 0.006145660329519638])</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.fit</code><code class="nohighlight hljs ansi" style="display:block;">────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      t  Pr(&gt;|t|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  32.0137     4.63226      6.91    &lt;1e-06  22.5249     41.5024
HP           -0.0367861  0.00989146  -3.72    0.0009  -0.0570478  -0.0165243
WT           -3.19781    0.846546    -3.78    0.0008  -4.93188    -1.46374
Gear          1.01998    0.851408     1.20    0.2410  -0.72405     2.76401
────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.sigma</code><code class="nohighlight hljs ansi" style="display:block;">2.5741691724978977</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.LogLike</code><code class="nohighlight hljs ansi" style="display:block;">-73.52638935960971</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.AIC</code><code class="nohighlight hljs ansi" style="display:block;">157.05277871921942</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.BIC</code><code class="nohighlight hljs ansi" style="display:block;">164.38145823321804</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.R_sqr</code><code class="nohighlight hljs ansi" style="display:block;">0.8352309600685555</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.Adjusted_R_sqr</code><code class="nohighlight hljs ansi" style="display:block;">0.8175771343616149</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.fittedResponse</code><code class="nohighlight hljs ansi" style="display:block;">32-element Vector{Float64}:
 23.668849952338704
 22.853408243206346
 25.253556140740866
 20.746171762311327
 17.63557054383011
 20.146638453886396
 14.644831040166551
 23.61182872351377
 22.525801204993858
 20.5684264750049
  ⋮
 13.781422171673466
 16.34045724109048
 27.477936821121038
 26.92271503957491
 28.118449005198737
 17.264981908248625
 21.818065399379666
 13.37404747719859
 23.193986311384343</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.residuals</code><code class="nohighlight hljs ansi" style="display:block;">32-element Vector{Float64}:
 -2.6688499523387037
 -1.8534082432063457
 -2.453556140740865
  0.6538282376886713
  1.06442945616989
 -2.046638453886395
 -0.3448310401665502
  0.7881712764862279
  0.27419879500614286
 -1.3684264750049024
  ⋮
 -0.481422171673465
  2.8595427589095195
 -0.17793682112103681
 -0.9227150395749106
  2.281550994801261
 -1.4649819082486246
 -2.1180653993796668
  1.6259525228014091
 -1.7939863113843444</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_1.Cooks_distance</code><code class="nohighlight hljs ansi" style="display:block;">32-element Vector{Float64}:
 0.013342034282302684
 0.00688728266731234
 0.015495847517058797
 0.0014309089637600369
 0.004471979213924145
 0.014588985833724696
 0.0015401004198812064
 0.005826402580870707
 0.0003074315682457445
 0.007011803724485943
 ⋮
 0.0020768256096929424
 0.02203970419212919
 0.0001378106083284689
 0.006862929526075293
 0.047038899451778936
 0.0381204513180911
 0.03540469459036285
 0.13715341355042346
 0.006145660329519638</code></pre><p><strong>Linear Regression - Ridge Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_2 = @fitmodel((MPG ~ HP + WT+Gear),df,LinearRegression(),Prior_Ridge())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_2.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           v    6.7856    3.8401     0.0384    0.0628   3441.7118    0.9999    ⋯
           σ    2.6902    0.3912     0.0039    0.0063   3463.6088    1.0014    ⋯
           α   28.4871    5.3986     0.0540    0.0982   2709.2752    0.9999    ⋯
        β[1]   -0.0399    0.0106     0.0001    0.0002   3648.1395    1.0000    ⋯
        β[2]   -2.6666    0.9602     0.0096    0.0166   2840.2374    1.0000    ⋯
        β[3]    1.6261    0.9814     0.0098    0.0175   2862.6159    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_2.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           v    2.4464    4.4121    5.9310    8.0069   16.5097
           σ    2.0580    2.4174    2.6374    2.9095    3.6098
           α   17.3528   25.2000   28.6709   32.1123   38.4808
        β[1]   -0.0615   -0.0465   -0.0397   -0.0329   -0.0195
        β[2]   -4.4720   -3.2918   -2.6864   -2.0889   -0.6711
        β[3]   -0.2128    0.9729    1.5920    2.2378    3.6782</code></pre><p><strong>Linear Regression - Laplace Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_3 = @fitmodel((MPG ~ HP + WT+Gear),df,LinearRegression(),Prior_Laplace())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_3.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           v    4.3044    3.0965     0.0310    0.0428   4460.0552    1.0000    ⋯
           σ    2.6660    0.3802     0.0038    0.0054   4506.2616    1.0000    ⋯
           α   29.4072    5.1031     0.0510    0.0996   2821.5791    1.0002    ⋯
        β[1]   -0.0393    0.0103     0.0001    0.0002   3814.6262    1.0000    ⋯
        β[2]   -2.7765    0.9118     0.0091    0.0166   2736.6432    1.0001    ⋯
        β[3]    1.4537    0.9303     0.0093    0.0177   3001.7000    1.0001    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_3.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           v    1.2961    2.4232    3.4599    5.1485   12.5397
           σ    2.0392    2.3978    2.6239    2.8874    3.5252
           α   18.7467   26.1038   29.5437   32.8871   38.7135
        β[1]   -0.0602   -0.0460   -0.0391   -0.0325   -0.0196
        β[2]   -4.5095   -3.4038   -2.8011   -2.1795   -0.9010
        β[3]   -0.2641    0.8150    1.4232    2.0550    3.4161</code></pre><p><strong>Linear Regression - Cauchy Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_4 = @fitmodel((MPG ~ HP + WT+Gear),df,LinearRegression(),Prior_Cauchy(),20000)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (20000×17×1 Array{Float64, 3}), Summary Statistics (5 x 8), Quantiles (5 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_4.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           σ    2.5892    0.3488     0.0025    0.0038   8556.3104    1.0000    ⋯
           α   30.2670    4.6034     0.0326    0.0598   5385.7837    1.0000    ⋯
        β[1]   -0.0394    0.0099     0.0001    0.0001   8140.1773    1.0000    ⋯
        β[2]   -2.8333    0.8519     0.0060    0.0104   5939.9031    1.0000    ⋯
        β[3]    1.2736    0.8416     0.0060    0.0108   5642.6232    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_4.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           σ    2.0178    2.3385    2.5540    2.7979    3.3742
           α   20.7779   27.3470   30.3360   33.2981   39.1351
        β[1]   -0.0591   -0.0459   -0.0393   -0.0328   -0.0196
        β[2]   -4.4571   -3.4031   -2.8435   -2.2758   -1.1351
        β[3]   -0.3654    0.7166    1.2595    1.8066    3.0009</code></pre><p><strong>Linear Regression - T-Distributed Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_5 = @fitmodel((MPG ~ HP + WT+Gear),df,LinearRegression(),Prior_TDist())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_5.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           ν    1.0438    0.5659     0.0057    0.0073   5543.6913    0.9999    ⋯
           σ    2.6244    0.3560     0.0036    0.0051   5205.9489    0.9999    ⋯
           α   30.3061    4.6884     0.0469    0.0807   2949.3346    1.0000    ⋯
        β[1]   -0.0394    0.0100     0.0001    0.0001   4357.4310    1.0002    ⋯
        β[2]   -2.8320    0.8591     0.0086    0.0150   3116.2706    1.0000    ⋯
        β[3]    1.2639    0.8546     0.0085    0.0139   3181.0152    1.0001    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_5.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           ν    0.3821    0.6733    0.9166    1.2554    2.4628
           σ    2.0405    2.3722    2.5870    2.8250    3.4529
           α   20.6204   27.2592   30.5092   33.4551   38.9658
        β[1]   -0.0595   -0.0460   -0.0393   -0.0327   -0.0199
        β[2]   -4.4708   -3.4079   -2.8622   -2.2742   -1.0850
        β[3]   -0.3239    0.6752    1.2319    1.8103    3.0164</code></pre><p><strong>Linear Regression - Uniform Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_6 = @fitmodel((MPG ~ HP + WT+Gear),df,LinearRegression(),Prior_TDist())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_6.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           ν    1.0491    0.5728     0.0057    0.0067   5370.6377    0.9999    ⋯
           σ    2.6249    0.3618     0.0036    0.0066   4115.4944    0.9999    ⋯
           α   30.2092    4.7793     0.0478    0.0856   2453.4381    1.0000    ⋯
        β[1]   -0.0396    0.0102     0.0001    0.0002   3758.2866    0.9999    ⋯
        β[2]   -2.8165    0.8938     0.0089    0.0165   2568.6507    1.0003    ⋯
        β[3]    1.2854    0.8641     0.0086    0.0149   2663.7989    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m1_6.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           ν    0.3788    0.6670    0.9163    1.2793    2.4957
           σ    2.0388    2.3695    2.5880    2.8313    3.4545
           α   20.4506   27.1519   30.3316   33.4255   39.3701
        β[1]   -0.0601   -0.0465   -0.0395   -0.0327   -0.0199
        β[2]   -4.5216   -3.4240   -2.8350   -2.2225   -1.0385
        β[3]   -0.3452    0.7021    1.2705    1.8289    3.0749</code></pre><h2 id="Example-2:-Logistic-Regression"><a class="docs-heading-anchor" href="#Example-2:-Logistic-Regression">Example 2: Logistic Regression</a><a id="Example-2:-Logistic-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-Logistic-Regression" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; turnout = dataset(&quot;Zelig&quot;, &quot;turnout&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">2000×5 DataFrame
  Row │ Race   Age    Educate  Income   Vote
      │ Cat…   Int32  Float64  Float64  Int32
──────┼───────────────────────────────────────
    1 │ white     60     14.0   3.3458      1
    2 │ white     51     10.0   1.8561      0
    3 │ white     24     12.0   0.6304      0
    4 │ white     38      8.0   3.4183      1
    5 │ white     25     12.0   2.7852      1
    6 │ white     67     12.0   2.3866      1
    7 │ white     40     12.0   4.2857      0
    8 │ white     56     10.0   9.3205      1
  ⋮   │   ⋮      ⋮       ⋮        ⋮       ⋮
 1994 │ white     58     12.0   0.1936      0
 1995 │ white     22      7.0   0.2364      0
 1996 │ white     26     16.0   3.3834      0
 1997 │ white     34     12.0   2.917       1
 1998 │ white     51     16.0   7.8949      1
 1999 │ white     22     10.0   2.4811      0
 2000 │ white     59     10.0   0.5523      0
                             1985 rows omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_1 = @fitmodel((Vote ~ Age + Race +Income + Educate)
                       ,turnout,LogisticRegression(),Logit())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_logistic_Binom_NIP_Optim(Vote ~ Age + Race + Income + Educate, &quot;LogisticReg&quot;, &quot;Binomial&quot;, &quot;NIP&quot;, &quot;LogitLink&quot;, &quot;Optimization&quot;, ────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  -3.03426    0.325927    -9.31    &lt;1e-19  -3.67307    -2.39546
Age           0.0283543  0.00346034   8.19    &lt;1e-15   0.0215722   0.0351365
Race: white   0.250798   0.146457     1.71    0.0868  -0.0362521   0.537847
Income        0.177112   0.0271516    6.52    &lt;1e-10   0.123896    0.230328
Educate       0.175634   0.0203308    8.64    &lt;1e-17   0.135786    0.215481
────────────────────────────────────────────────────────────────────────────, [-3.0342607596659574, 0.028354326662967565, 0.25079767698792804, 0.17711170678607488, 0.1756335923685919], -1011.9906318515575, -1011.9906318515575, 2033.981263703115, 2061.9857760008254)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_1.fit</code><code class="nohighlight hljs ansi" style="display:block;">────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  -3.03426    0.325927    -9.31    &lt;1e-19  -3.67307    -2.39546
Age           0.0283543  0.00346034   8.19    &lt;1e-15   0.0215722   0.0351365
Race: white   0.250798   0.146457     1.71    0.0868  -0.0362521   0.537847
Income        0.177112   0.0271516    6.52    &lt;1e-10   0.123896    0.230328
Educate       0.175634   0.0203308    8.64    &lt;1e-17   0.135786    0.215481
────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_1.modelClass</code><code class="nohighlight hljs ansi" style="display:block;">&quot;LogisticReg&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_1.LogLike</code><code class="nohighlight hljs ansi" style="display:block;">-1011.9906318515575</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_1.AIC</code><code class="nohighlight hljs ansi" style="display:block;">2033.981263703115</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_1.BIC</code><code class="nohighlight hljs ansi" style="display:block;">2061.9857760008254</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_2 = @fitmodel((Vote ~ Age + Race +Income + Educate)
                       ,turnout,LogisticRegression(),Probit())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_logistic_Binom_NIP_Optim(Vote ~ Age + Race + Income + Educate, &quot;LogisticReg&quot;, &quot;Binomial&quot;, &quot;NIP&quot;, &quot;ProbitLink&quot;, &quot;Optimization&quot;, ────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  -1.76141    0.188556    -9.34    &lt;1e-20  -2.13097    -1.39185
Age           0.0164973  0.00199897   8.25    &lt;1e-15   0.0125794   0.0204152
Race: white   0.162856   0.0876885    1.86    0.0633  -0.0090108   0.334722
Income        0.0963117  0.0149675    6.43    &lt;1e-09   0.066976    0.125647
Educate       0.10417    0.0116713    8.93    &lt;1e-18   0.0812949   0.127046
────────────────────────────────────────────────────────────────────────────, [-1.761408163117118, 0.016497320078788253, 0.16285552041055626, 0.09631170663551415, 0.10417031249322409], -1012.0982569695421, -1012.0982569695421, 2034.1965139390843, 2062.201026236795)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_2.fit</code><code class="nohighlight hljs ansi" style="display:block;">────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  -1.76141    0.188556    -9.34    &lt;1e-20  -2.13097    -1.39185
Age           0.0164973  0.00199897   8.25    &lt;1e-15   0.0125794   0.0204152
Race: white   0.162856   0.0876885    1.86    0.0633  -0.0090108   0.334722
Income        0.0963117  0.0149675    6.43    &lt;1e-09   0.066976    0.125647
Educate       0.10417    0.0116713    8.93    &lt;1e-18   0.0812949   0.127046
────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_2.BIC</code><code class="nohighlight hljs ansi" style="display:block;">2062.201026236795</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_3 = @fitmodel((Vote ~ Age + Race +Income + Educate)
                       ,turnout,LogisticRegression(),Cloglog())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_logistic_Binom_NIP_Optim(Vote ~ Age + Race + Income + Educate, &quot;LogisticReg&quot;, &quot;Binomial&quot;, &quot;NIP&quot;, &quot;CloglogLink&quot;, &quot;Optimization&quot;, ─────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error       z  Pr(&gt;|z|)   Lower 95%   Upper 95%
─────────────────────────────────────────────────────────────────────────────
(Intercept)  -1.94617    0.184123    -10.57    &lt;1e-25  -2.30704    -1.58529
Age           0.0147857  0.00184088    8.03    &lt;1e-15   0.0111776   0.0183937
Race: white   0.185139   0.087101      2.13    0.0335   0.014424    0.355854
Income        0.0768268  0.0126411     6.08    &lt;1e-08   0.0520506   0.101603
Educate       0.0983976  0.0108857     9.04    &lt;1e-18   0.077062    0.119733
─────────────────────────────────────────────────────────────────────────────, [-1.9461658888560365, 0.01478565292775795, 0.1851389231866392, 0.07682681046022045, 0.09839764452796898], -1013.3450607257502, -1013.3450607257502, 2036.6901214515003, 2064.694633749211)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_3.fit</code><code class="nohighlight hljs ansi" style="display:block;">─────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error       z  Pr(&gt;|z|)   Lower 95%   Upper 95%
─────────────────────────────────────────────────────────────────────────────
(Intercept)  -1.94617    0.184123    -10.57    &lt;1e-25  -2.30704    -1.58529
Age           0.0147857  0.00184088    8.03    &lt;1e-15   0.0111776   0.0183937
Race: white   0.185139   0.087101      2.13    0.0335   0.014424    0.355854
Income        0.0768268  0.0126411     6.08    &lt;1e-08   0.0520506   0.101603
Educate       0.0983976  0.0108857     9.04    &lt;1e-18   0.077062    0.119733
─────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_3.BIC</code><code class="nohighlight hljs ansi" style="display:block;">2064.694633749211</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_4 = @fitmodel((Vote ~ Age + Race +Income + Educate)
                       ,turnout,LogisticRegression(),Cauchit())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_logistic_Binom_NIP_Optim(Vote ~ Age + Race + Income + Educate, &quot;LogisticReg&quot;, &quot;Binomial&quot;, &quot;NIP&quot;, &quot;CauchitLink&quot;, &quot;Optimization&quot;, ────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  -3.16889    0.384429    -8.24    &lt;1e-15  -3.92235    -2.41542
Age           0.0304105  0.00413473   7.35    &lt;1e-12   0.0223066   0.0385144
Race: white   0.181839   0.144766     1.26    0.2091  -0.101898    0.465576
Income        0.235267   0.038152     6.17    &lt;1e-09   0.16049     0.310043
Educate       0.169276   0.0240098    7.05    &lt;1e-11   0.122217    0.216334
────────────────────────────────────────────────────────────────────────────, [-3.1688856937644476, 0.030410485457771943, 0.1818392864361941, 0.23526695558678265, 0.16927583633091853], -1020.4709747263992, -1020.4709747263992, 2050.9419494527983, 2078.9464617505087)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_4.fit</code><code class="nohighlight hljs ansi" style="display:block;">────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)  -3.16889    0.384429    -8.24    &lt;1e-15  -3.92235    -2.41542
Age           0.0304105  0.00413473   7.35    &lt;1e-12   0.0223066   0.0385144
Race: white   0.181839   0.144766     1.26    0.2091  -0.101898    0.465576
Income        0.235267   0.038152     6.17    &lt;1e-09   0.16049     0.310043
Educate       0.169276   0.0240098    7.05    &lt;1e-11   0.122217    0.216334
────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_4.BIC</code><code class="nohighlight hljs ansi" style="display:block;">2078.9464617505087</code></pre><p><strong>Logistic Regression - with Ridge Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_5 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Logit(),Prior_Ridge())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_5.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   es ⋯
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64      ⋯

           λ    1.4349    0.7075     0.0071    0.0705   21.6489    1.1418      ⋯
        β[1]   -2.6539    0.4053     0.0041    0.0400   22.6689    1.1574      ⋯
        β[2]    0.0763    0.1387     0.0014    0.0138   21.8756    1.1359      ⋯
        β[3]    0.3396    0.3914     0.0039    0.0387   22.6632    1.1775      ⋯
        β[4]    0.3322    0.4203     0.0042    0.0420   21.9696    1.1410      ⋯
        β[5]   -0.0779    0.6605     0.0066    0.0661   21.6624    1.1473      ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_5.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.6803    0.9639    1.1769    1.5699    3.0882
        β[1]   -3.4952   -2.9021   -2.6659   -2.3987   -2.0105
        β[2]    0.0193    0.0241    0.0267    0.0299    0.4659
        β[3]   -0.0863    0.1206    0.2243    0.3637    1.3127
        β[4]    0.1262    0.1628    0.1825    0.2068    1.4864
        β[5]   -1.9764    0.1410    0.1575    0.1726    0.2050</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_6 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Probit(),Prior_Ridge(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_6.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.8959    0.3479     0.0035    0.0050   5008.4444    0.9999    ⋯
        β[1]   -1.6685    0.1906     0.0019    0.0026   4982.4171    0.9999    ⋯
        β[2]    0.0158    0.0020     0.0000    0.0000   7477.3211    1.0000    ⋯
        β[3]    0.1500    0.0880     0.0009    0.0011   6876.2534    0.9999    ⋯
        β[4]    0.0964    0.0149     0.0001    0.0002   5599.5859    0.9999    ⋯
        β[5]    0.0999    0.0118     0.0001    0.0001   5135.7305    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_6.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.4652    0.6678    0.8174    1.0378    1.7714
        β[1]   -2.0440   -1.7963   -1.6686   -1.5417   -1.2962
        β[2]    0.0119    0.0145    0.0158    0.0171    0.0197
        β[3]   -0.0295    0.0916    0.1506    0.2096    0.3217
        β[4]    0.0674    0.0863    0.0962    0.1065    0.1254
        β[5]    0.0770    0.0922    0.0998    0.1077    0.1232</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_7 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cloglog(),Prior_Ridge(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_7.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   es ⋯
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64      ⋯

           λ    0.8750    0.0004     0.0000    0.0000   24.2142    1.0797      ⋯
        β[1]    1.5936    0.0005     0.0000    0.0001   22.4071    1.3143      ⋯
        β[2]   -0.0463    0.0057     0.0001    0.0006   20.2540    2.7206      ⋯
        β[3]   -0.1853    0.0005     0.0000    0.0000   24.5031    1.1916      ⋯
        β[4]   -1.2749    0.0038     0.0000    0.0004   20.2335    2.9432      ⋯
        β[5]    0.2116    0.0094     0.0001    0.0009   20.2534    2.7356      ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_7.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.8743    0.8748    0.8750    0.8753    0.8757
        β[1]    1.5928    1.5933    1.5936    1.5940    1.5946
        β[2]   -0.0549   -0.0518   -0.0460   -0.0413   -0.0366
        β[3]   -0.1864   -0.1857   -0.1853   -0.1850   -0.1845
        β[4]   -1.2806   -1.2788   -1.2741   -1.2713   -1.2694
        β[5]    0.1957    0.2034    0.2112    0.2207    0.2257</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_8 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cauchit(),Prior_Ridge(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_8.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    1.5191    0.6019     0.0060    0.0083   5098.7972    1.0000    ⋯
        β[1]   -2.9733    0.3862     0.0039    0.0053   4230.2236    0.9999    ⋯
        β[2]    0.0287    0.0043     0.0000    0.0001   5515.9396    0.9999    ⋯
        β[3]    0.1599    0.1529     0.0015    0.0019   6548.6193    0.9999    ⋯
        β[4]    0.2384    0.0400     0.0004    0.0005   6849.8073    0.9999    ⋯
        β[5]    0.1596    0.0239     0.0002    0.0003   4481.4139    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_8.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.7758    1.1235    1.3849    1.7611    3.0471
        β[1]   -3.7590   -3.2296   -2.9595   -2.7113   -2.2317
        β[2]    0.0204    0.0258    0.0287    0.0316    0.0375
        β[3]   -0.1472    0.0568    0.1641    0.2623    0.4533
        β[4]    0.1622    0.2109    0.2377    0.2643    0.3206
        β[5]    0.1135    0.1434    0.1592    0.1752    0.2078</code></pre><p><strong>Logistic Regression - with Laplace Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_9 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Logit(),Prior_Laplace())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_9.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.8532    0.4786     0.0048    0.0062   4920.0068    1.0006    ⋯
        β[1]   -2.8690    0.3306     0.0033    0.0051   4266.3089    1.0000    ⋯
        β[2]    0.0273    0.0035     0.0000    0.0000   6272.3178    1.0000    ⋯
        β[3]    0.2096    0.1444     0.0014    0.0015   7284.1396    0.9999    ⋯
        β[4]    0.1772    0.0273     0.0003    0.0003   6108.6418    1.0000    ⋯
        β[5]    0.1687    0.0202     0.0002    0.0003   4728.6103    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_9.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.3255    0.5432    0.7299    1.0168    2.1199
        β[1]   -3.5188   -3.0899   -2.8638   -2.6448   -2.2310
        β[2]    0.0205    0.0249    0.0273    0.0296    0.0342
        β[3]   -0.0621    0.1073    0.2078    0.3066    0.4963
        β[4]    0.1245    0.1589    0.1768    0.1949    0.2318
        β[5]    0.1296    0.1552    0.1687    0.1822    0.2083</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_10 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Probit(),Prior_Laplace())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_10.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   es ⋯
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64      ⋯

           λ    2.0898    0.0008     0.0000    0.0001   21.8688    1.4130      ⋯
        β[1]   -0.4729    0.0008     0.0000    0.0001   20.3804    2.6625      ⋯
        β[2]   -3.1498    0.0048     0.0000    0.0005   20.2626    2.6290      ⋯
        β[3]   -0.7205    0.0003     0.0000    0.0000   23.7173    1.0647      ⋯
        β[4]    3.7267    0.0025     0.0000    0.0003   20.3226    2.4149      ⋯
        β[5]    5.3796    0.0057     0.0001    0.0006   20.2607    2.6485      ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_10.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    2.0885    2.0892    2.0897    2.0904    2.0913
        β[1]   -0.4743   -0.4736   -0.4729   -0.4721   -0.4717
        β[2]   -3.1576   -3.1540   -3.1499   -3.1455   -3.1418
        β[3]   -0.7210   -0.7207   -0.7206   -0.7203   -0.7198
        β[4]    3.7226    3.7249    3.7265    3.7286    3.7310
        β[5]    5.3702    5.3745    5.3797    5.3846    5.3887</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_11 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cloglog(),Prior_Laplace(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_11.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.9016    0.4514     0.0045    0.0073   5078.1929    1.0001    ⋯
        β[1]   -2.8810    0.3320     0.0033    0.0050   5255.4540    1.0006    ⋯
        β[2]    0.0274    0.0035     0.0000    0.0000   7063.7159    1.0005    ⋯
        β[3]    0.2098    0.1440     0.0014    0.0020   5799.3506    0.9999    ⋯
        β[4]    0.1778    0.0269     0.0003    0.0003   8833.1370    1.0000    ⋯
        β[5]    0.1693    0.0205     0.0002    0.0003   5729.7951    1.0003    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_11.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.3671    0.6015    0.7934    1.0790    2.0752
        β[1]   -3.5384   -3.1070   -2.8799   -2.6547   -2.2477
        β[2]    0.0206    0.0250    0.0273    0.0297    0.0343
        β[3]   -0.0651    0.1097    0.2101    0.3067    0.4936
        β[4]    0.1250    0.1595    0.1779    0.1963    0.2306
        β[5]    0.1300    0.1551    0.1693    0.1831    0.2093</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_12 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cauchit(),Prior_Laplace(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_12.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.8855    0.4561     0.0046    0.0058   5150.3787    0.9999    ⋯
        β[1]   -2.8780    0.3297     0.0033    0.0040   5114.2297    1.0000    ⋯
        β[2]    0.0274    0.0035     0.0000    0.0000   6884.2119    1.0001    ⋯
        β[3]    0.2108    0.1437     0.0014    0.0017   7190.5252    1.0000    ⋯
        β[4]    0.1778    0.0272     0.0003    0.0003   8154.2885    0.9999    ⋯
        β[5]    0.1690    0.0205     0.0002    0.0002   5452.7817    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_12.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.3767    0.5935    0.7761    1.0564    2.0017
        β[1]   -3.5247   -3.0966   -2.8759   -2.6555   -2.2299
        β[2]    0.0205    0.0250    0.0273    0.0297    0.0343
        β[3]   -0.0652    0.1127    0.2090    0.3073    0.4942
        β[4]    0.1252    0.1595    0.1774    0.1959    0.2320
        β[5]    0.1299    0.1551    0.1686    0.1830    0.2095</code></pre><p><strong>Logistic Regression - with Cauchy Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_13 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Logit(),Prior_Cauchy(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_13.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.3068    0.2437     0.0024    0.0033   5910.2229    1.0006    ⋯
        β[1]   -2.9178    0.3340     0.0033    0.0044   5219.1006    1.0001    ⋯
        β[2]    0.0279    0.0035     0.0000    0.0000   7166.9099    1.0001    ⋯
        β[3]    0.1783    0.1426     0.0014    0.0018   6995.1244    0.9999    ⋯
        β[4]    0.1768    0.0272     0.0003    0.0003   7659.0036    1.0000    ⋯
        β[5]    0.1728    0.0207     0.0002    0.0003   4951.4990    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_13.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.0640    0.1567    0.2424    0.3796    0.9429
        β[1]   -3.5852   -3.1428   -2.9144   -2.6952   -2.2697
        β[2]    0.0212    0.0256    0.0279    0.0303    0.0348
        β[3]   -0.0755    0.0756    0.1699    0.2732    0.4776
        β[4]    0.1233    0.1583    0.1763    0.1953    0.2304
        β[5]    0.1326    0.1586    0.1729    0.1867    0.2136</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_14 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Probit(),Prior_Cauchy(),2.0,30000)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_14.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.3074    0.2368     0.0024    0.0030   5569.2217    1.0002    ⋯
        β[1]   -2.9129    0.3243     0.0032    0.0041   5274.1899    1.0002    ⋯
        β[2]    0.0279    0.0034     0.0000    0.0000   7307.0495    1.0001    ⋯
        β[3]    0.1796    0.1377     0.0014    0.0017   6695.5724    1.0001    ⋯
        β[4]    0.1769    0.0273     0.0003    0.0003   7400.6300    0.9999    ⋯
        β[5]    0.1725    0.0203     0.0002    0.0002   5561.4576    1.0003    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_14.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.0695    0.1574    0.2432    0.3791    0.9420
        β[1]   -3.5625   -3.1305   -2.9106   -2.6866   -2.2897
        β[2]    0.0213    0.0255    0.0278    0.0302    0.0346
        β[3]   -0.0659    0.0776    0.1758    0.2741    0.4582
        β[4]    0.1244    0.1582    0.1764    0.1953    0.2313
        β[5]    0.1334    0.1586    0.1724    0.1855    0.2134</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_15 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cloglog(),Prior_Cauchy(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_15.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   es ⋯
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64      ⋯

           λ    1.0562    0.2781     0.0028    0.0279   20.4727    1.9711      ⋯
        β[1]   -5.8309    0.6819     0.0068    0.0685   20.3808    2.0372      ⋯
        β[2]    0.2252    0.2456     0.0025    0.0247   20.5376    1.8108      ⋯
        β[3]   -0.4209    0.9794     0.0098    0.0984   20.2468    3.0796      ⋯
        β[4]   -0.2996    0.6811     0.0068    0.0683   20.5541    1.7499      ⋯
        β[5]   -0.0477    0.5032     0.0050    0.0504   20.6829    1.6152      ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_15.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.5671    0.8622    1.0289    1.3714    1.3753
        β[1]   -6.5320   -6.5291   -5.9398   -5.3059   -4.4049
        β[2]    0.0375    0.0459    0.0542    0.5674    0.5726
        β[3]   -1.6624   -1.6587    0.1069    0.4744    0.6326
        β[4]   -1.2657   -1.2403    0.1691    0.2037    0.2508
        β[5]   -0.8405   -0.7089    0.2721    0.3169    0.4107</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_16 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cauchit(),Prior_Cauchy(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_16.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.3066    0.2317     0.0023    0.0031   5591.9712    1.0000    ⋯
        β[1]   -2.9234    0.3269     0.0033    0.0044   5066.7404    0.9999    ⋯
        β[2]    0.0279    0.0034     0.0000    0.0000   7180.4990    0.9999    ⋯
        β[3]    0.1781    0.1394     0.0014    0.0020   5867.0338    1.0000    ⋯
        β[4]    0.1762    0.0267     0.0003    0.0003   6401.4570    0.9999    ⋯
        β[5]    0.1733    0.0202     0.0002    0.0003   5459.3920    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_16.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.0676    0.1563    0.2443    0.3863    0.8894
        β[1]   -3.5748   -3.1399   -2.9179   -2.7043   -2.2978
        β[2]    0.0213    0.0256    0.0279    0.0303    0.0346
        β[3]   -0.0652    0.0756    0.1693    0.2698    0.4687
        β[4]    0.1244    0.1579    0.1763    0.1942    0.2292
        β[5]    0.1340    0.1595    0.1732    0.1869    0.2137</code></pre><p><strong>Logistic Regression - with T-Dist Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_17 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Logit(),Prior_TDist(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_17.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   es ⋯
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64      ⋯

           λ    3.2694    0.0026     0.0000    0.0003   21.1779    1.9815      ⋯
           ν    1.6713    0.0008     0.0000    0.0001   24.0585    1.0475      ⋯
        β[1]    7.4290    0.0007     0.0000    0.0001   21.4082    1.6290      ⋯
        β[2]   -0.7883    0.0055     0.0001    0.0006   20.2708    2.6100      ⋯
        β[3]    5.5649    0.0012     0.0000    0.0001   20.6436    1.9373      ⋯
        β[4]   -2.2964    0.0020     0.0000    0.0002   20.3073    2.4481      ⋯
        β[5]    2.5711    0.0089     0.0001    0.0009   20.2693    2.6199      ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_17.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    3.2658    3.2673    3.2687    3.2712    3.2756
           ν    1.6693    1.6709    1.6713    1.6719    1.6727
        β[1]    7.4277    7.4285    7.4290    7.4294    7.4301
        β[2]   -0.7977   -0.7928   -0.7880   -0.7835   -0.7795
        β[3]    5.5632    5.5641    5.5646    5.5659    5.5672
        β[4]   -2.2993   -2.2979   -2.2969   -2.2944   -2.2930
        β[5]    2.5568    2.5632    2.5705    2.5783    2.5862</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_18 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Probit(),Prior_TDist(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_18.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   es ⋯
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64      ⋯

           λ    3.4133    0.0039     0.0000    0.0004   20.5459    1.6156      ⋯
           ν    3.5524    0.0037     0.0000    0.0004   20.4926    2.4003      ⋯
        β[1]   -2.5695    0.0008     0.0000    0.0001   20.5889    1.7941      ⋯
        β[2]    0.4775    0.0001     0.0000    0.0000   20.6505    2.3398      ⋯
        β[3]    3.4509    0.0015     0.0000    0.0001   20.3783    1.9328      ⋯
        β[4]    0.1760    0.0042     0.0000    0.0004   20.2558    2.5532      ⋯
        β[5]   -3.1235    0.0094     0.0001    0.0009   20.2694    2.5655      ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_18.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    3.4070    3.4099    3.4133    3.4166    3.4198
           ν    3.5471    3.5491    3.5513    3.5563    3.5587
        β[1]   -2.5714   -2.5698   -2.5693   -2.5690   -2.5683
        β[2]    0.4773    0.4774    0.4775    0.4776    0.4777
        β[3]    3.4481    3.4497    3.4512    3.4522    3.4528
        β[4]    0.1690    0.1727    0.1763    0.1793    0.1829
        β[5]   -3.1390   -3.1313   -3.1228   -3.1158   -3.1075</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_19 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cloglog(),Prior_TDist(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_19.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.5309    0.3694     0.0037    0.0063   3771.5770    1.0001    ⋯
           ν    2.0646    7.4604     0.0746    0.1347   3451.9300    1.0005    ⋯
        β[1]   -2.9339    0.3205     0.0032    0.0044   5183.3723    1.0000    ⋯
        β[2]    0.0279    0.0034     0.0000    0.0000   6971.1178    0.9999    ⋯
        β[3]    0.2070    0.1394     0.0014    0.0015   8264.8338    1.0008    ⋯
        β[4]    0.1775    0.0276     0.0003    0.0003   8147.3867    1.0006    ⋯
        β[5]    0.1722    0.0201     0.0002    0.0003   5582.2393    1.0001    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_19.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.1729    0.3058    0.4276    0.6326    1.4826
           ν    0.3627    0.7530    1.1587    1.8725    7.2794
        β[1]   -3.5640   -3.1476   -2.9363   -2.7188   -2.3074
        β[2]    0.0213    0.0255    0.0279    0.0301    0.0347
        β[3]   -0.0628    0.1119    0.2056    0.2991    0.4854
        β[4]    0.1245    0.1585    0.1775    0.1963    0.2315
        β[5]    0.1333    0.1586    0.1720    0.1858    0.2114</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_20 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cauchit(),Prior_TDist(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_20.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.5180    0.3323     0.0033    0.0051   4697.2231    0.9999    ⋯
           ν    1.9107    6.5350     0.0653    0.1051   3939.3525    1.0000    ⋯
        β[1]   -2.9234    0.3237     0.0032    0.0050   5129.4453    1.0003    ⋯
        β[2]    0.0277    0.0034     0.0000    0.0000   7133.7057    1.0004    ⋯
        β[3]    0.2037    0.1401     0.0014    0.0016   7073.9254    0.9999    ⋯
        β[4]    0.1771    0.0270     0.0003    0.0003   6534.9719    0.9999    ⋯
        β[5]    0.1721    0.0202     0.0002    0.0003   5422.6447    1.0002    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_20.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.1726    0.3027    0.4231    0.6215    1.3996
           ν    0.3840    0.7703    1.1661    1.8491    6.4722
        β[1]   -3.5691   -3.1380   -2.9211   -2.7082   -2.2937
        β[2]    0.0212    0.0254    0.0277    0.0301    0.0345
        β[3]   -0.0617    0.1074    0.1999    0.2993    0.4804
        β[4]    0.1245    0.1589    0.1769    0.1949    0.2312
        β[5]    0.1317    0.1587    0.1720    0.1853    0.2111</code></pre><p><strong>Logistic Regression - with Uniform Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_21 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Logit(),Prior_Uniform(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_21.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean        std   naive_se      mcse         ess      rhat   ⋯
      Symbol   Float64    Float64    Float64   Float64     Float64   Float64   ⋯

           v   19.1404   336.1253     3.3613    6.7787   2439.5329    1.0004   ⋯
        β[1]   -0.5950     0.0000     0.0000    0.0000     20.5530    0.9999   ⋯
        β[2]    0.0100     0.0025     0.0000    0.0001    806.1281    1.0037   ⋯
        β[3]   -0.0334     0.2235     0.0022    0.0129    274.5457    1.0096   ⋯
        β[4]    0.1716     0.0263     0.0003    0.0004   6693.7445    1.0000   ⋯
        β[5]    0.0614     0.0145     0.0001    0.0005    645.6770    1.0036   ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_21.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           v    0.7740    1.4425    2.5996    5.7843   60.6522
        β[1]   -0.5950   -0.5950   -0.5950   -0.5950   -0.5950
        β[2]    0.0050    0.0083    0.0099    0.0116    0.0151
        β[3]   -0.5950   -0.1386   -0.0203    0.0949    0.4062
        β[4]    0.1206    0.1537    0.1717    0.1893    0.2238
        β[5]    0.0331    0.0521    0.0610    0.0707    0.0909</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_22 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Probit(),Prior_Uniform(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_22.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean        std   naive_se      mcse         ess      rhat   ⋯
      Symbol   Float64    Float64    Float64   Float64     Float64   Float64   ⋯

           v   16.4810   178.3998     1.7840    2.9606   3562.8991    0.9999   ⋯
        β[1]   -0.4493     0.0000     0.0000    0.0000     20.5530    0.9999   ⋯
        β[2]    0.0114     0.0021     0.0000    0.0000   8684.6363    1.0004   ⋯
        β[3]   -0.4493     0.0000     0.0000    0.0000     20.5530    0.9999   ⋯
        β[4]    0.1814     0.0263     0.0003    0.0003   7046.8002    1.0002   ⋯
        β[5]    0.0707     0.0114     0.0001    0.0002   7796.0014    1.0003   ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_22.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           v    0.6899    1.3892    2.5436    5.8307   77.1530
        β[1]   -0.4493   -0.4493   -0.4493   -0.4493   -0.4493
        β[2]    0.0073    0.0100    0.0114    0.0129    0.0156
        β[3]   -0.4493   -0.4493   -0.4493   -0.4493   -0.4493
        β[4]    0.1298    0.1638    0.1814    0.1992    0.2331
        β[5]    0.0485    0.0628    0.0707    0.0784    0.0929</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_23 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cloglog(),Prior_Uniform(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_23.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters       mean         std   naive_se      mcse         ess      rhat ⋯
      Symbol    Float64     Float64    Float64   Float64     Float64   Float64 ⋯

           v   128.5284   3959.9661    39.5997   80.6877   2389.7221    1.0003 ⋯
        β[1]    -3.0580      0.3337     0.0033    0.0047   4565.3246    0.9999 ⋯
        β[2]     0.0286      0.0035     0.0000    0.0000   6566.1429    1.0000 ⋯
        β[3]     0.2523      0.1448     0.0014    0.0018   5622.1291    1.0000 ⋯
        β[4]     0.1785      0.0275     0.0003    0.0003   6333.8235    0.9999 ⋯
        β[5]     0.1767      0.0208     0.0002    0.0003   5134.6423    0.9999 ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_23.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%      97.5%
      Symbol   Float64   Float64   Float64   Float64    Float64

           v    3.4894    5.7471    9.4646   19.7661   234.9908
        β[1]   -3.7139   -3.2816   -3.0543   -2.8331    -2.4063
        β[2]    0.0218    0.0262    0.0286    0.0310     0.0356
        β[3]   -0.0241    0.1549    0.2528    0.3498     0.5336
        β[4]    0.1251    0.1600    0.1781    0.1972     0.2325
        β[5]    0.1357    0.1627    0.1766    0.1907     0.2171</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_24 = @fitmodel((Vote ~ Age + Race +Income + Educate),turnout
                       ,LogisticRegression(),Cauchit(),Prior_Uniform(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×18×1 Array{Float64, 3}), Summary Statistics (6 x 8), Quantiles (6 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_24.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean        std   naive_se      mcse         ess      rhat   ⋯
      Symbol   Float64    Float64    Float64   Float64     Float64   Float64   ⋯

           v   41.9934   371.2289     3.7123    5.2933   4461.3682    0.9999   ⋯
        β[1]   -3.0575     0.3334     0.0033    0.0058   3581.7155    1.0002   ⋯
        β[2]    0.0286     0.0035     0.0000    0.0001   5479.3809    1.0000   ⋯
        β[3]    0.2489     0.1485     0.0015    0.0017   6132.2723    1.0000   ⋯
        β[4]    0.1779     0.0275     0.0003    0.0003   6697.2938    1.0000   ⋯
        β[5]    0.1771     0.0206     0.0002    0.0003   3981.5783    1.0001   ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m2_24.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%      97.5%
      Symbol   Float64   Float64   Float64   Float64    Float64

           v    3.4325    5.7682    9.7383   20.6584   208.3903
        β[1]   -3.7228   -3.2817   -3.0476   -2.8314    -2.4222
        β[2]    0.0216    0.0262    0.0286    0.0309     0.0355
        β[3]   -0.0435    0.1483    0.2498    0.3495     0.5390
        β[4]    0.1248    0.1589    0.1777    0.1958     0.2329
        β[5]    0.1370    0.1635    0.1768    0.1908     0.2178</code></pre><h2 id="Example-3:-Poisson-Regression"><a class="docs-heading-anchor" href="#Example-3:-Poisson-Regression">Example 3: Poisson Regression</a><a id="Example-3:-Poisson-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Example-3:-Poisson-Regression" title="Permalink"></a></h2><p><strong>Poisson Regression - Likelihood analysis</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; sanction = dataset(&quot;Zelig&quot;, &quot;sanction&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">78×8 DataFrame
 Row │ Mil    Coop   Target  Import  Export  Cost   Num    NCost
     │ Int32  Int32  Int32   Int32   Int32   Int32  Int32  Cat…
─────┼───────────────────────────────────────────────────────────────────
   1 │     1      4       3       1       1      4     15  major loss
   2 │     0      2       3       0       1      3      4  modest loss
   3 │     0      1       3       1       0      2      1  little effect
   4 │     1      1       3       1       1      2      1  little effect
   5 │     0      1       3       1       1      2      1  little effect
   6 │     0      1       3       0       1      2      1  little effect
   7 │     1      2       2       0       1      2      3  little effect
   8 │     0      1       3       0       0      2      3  little effect
  ⋮  │   ⋮      ⋮      ⋮       ⋮       ⋮       ⋮      ⋮          ⋮
  72 │     0      2       2       0       0      1      8  net gain
  73 │     1      3       1       1       1      2     14  little effect
  74 │     0      2       1       0       0      1      2  net gain
  75 │     0      1       3       0       1      2      1  little effect
  76 │     0      4       3       1       0      2     13  little effect
  77 │     0      1       2       0       0      1      1  net gain
  78 │     1      3       1       1       1      2     10  little effect
                                                          63 rows omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sanction</code><code class="nohighlight hljs ansi" style="display:block;">78×8 DataFrame
 Row │ Mil    Coop   Target  Import  Export  Cost   Num    NCost
     │ Int32  Int32  Int32   Int32   Int32   Int32  Int32  Cat…
─────┼───────────────────────────────────────────────────────────────────
   1 │     1      4       3       1       1      4     15  major loss
   2 │     0      2       3       0       1      3      4  modest loss
   3 │     0      1       3       1       0      2      1  little effect
   4 │     1      1       3       1       1      2      1  little effect
   5 │     0      1       3       1       1      2      1  little effect
   6 │     0      1       3       0       1      2      1  little effect
   7 │     1      2       2       0       1      2      3  little effect
   8 │     0      1       3       0       0      2      3  little effect
  ⋮  │   ⋮      ⋮      ⋮       ⋮       ⋮       ⋮      ⋮          ⋮
  72 │     0      2       2       0       0      1      8  net gain
  73 │     1      3       1       1       1      2     14  little effect
  74 │     0      2       1       0       0      1      2  net gain
  75 │     0      1       3       0       1      2      1  little effect
  76 │     0      4       3       1       0      2     13  little effect
  77 │     0      1       2       0       0      1      1  net gain
  78 │     1      3       1       1       1      2     10  little effect
                                                          63 rows omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_1 = @fitmodel((Num ~ Target + Coop + NCost), sanction,PoissonRegression())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_Poisson_Reg(Num ~ Target + Coop + NCost, ─────────────────────────────────────────────────────────────────────────────────
                        Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────────────
(Intercept)         -1.91392    0.261667   -7.31    &lt;1e-12  -2.42678    -1.40106
Target               0.157769   0.0653822   2.41    0.0158   0.0296218   0.285915
Coop                 1.15127    0.0561861  20.49    &lt;1e-92   1.04114     1.26139
NCost: major loss   -0.324051   0.230055   -1.41    0.1590  -0.774951    0.126848
NCost: modest loss   1.71973    0.100518   17.11    &lt;1e-64   1.52272     1.91674
NCost: net gain      0.463907   0.16992     2.73    0.0063   0.13087     0.796944
─────────────────────────────────────────────────────────────────────────────────, [-1.9139174143215671, 0.15776854672316454, 1.1512671677538402, -0.32405115738560614, 1.7197292626770253, 0.4639068572422839], -284.33693448347356, 580.6738689669471, 594.8141219270847)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_1.fit</code><code class="nohighlight hljs ansi" style="display:block;">─────────────────────────────────────────────────────────────────────────────────
                        Coef.  Std. Error      z  Pr(&gt;|z|)   Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────────────
(Intercept)         -1.91392    0.261667   -7.31    &lt;1e-12  -2.42678    -1.40106
Target               0.157769   0.0653822   2.41    0.0158   0.0296218   0.285915
Coop                 1.15127    0.0561861  20.49    &lt;1e-92   1.04114     1.26139
NCost: major loss   -0.324051   0.230055   -1.41    0.1590  -0.774951    0.126848
NCost: modest loss   1.71973    0.100518   17.11    &lt;1e-64   1.52272     1.91674
NCost: net gain      0.463907   0.16992     2.73    0.0063   0.13087     0.796944
─────────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_1.LogLike</code><code class="nohighlight hljs ansi" style="display:block;">-284.33693448347356</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_1.AIC</code><code class="nohighlight hljs ansi" style="display:block;">580.6738689669471</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_1.BIC</code><code class="nohighlight hljs ansi" style="display:block;">594.8141219270847</code></pre><p><strong>Poisson Regression with Ridge Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_2 = @fitmodel((Num ~ Target + Coop + NCost), sanction,PoissonRegression(),Prior_Ridge())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_2.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    1.3015    0.4719     0.0047    0.0059   5564.8154    0.9999    ⋯
           α   -1.7978    0.2589     0.0026    0.0041   4602.1454    1.0000    ⋯
        β[1]    0.1390    0.0651     0.0007    0.0009   6756.5550    1.0001    ⋯
        β[2]    1.1328    0.0554     0.0006    0.0007   5648.6531    1.0000    ⋯
        β[3]   -0.3247    0.2265     0.0023    0.0027   7379.6654    1.0000    ⋯
        β[4]    1.6990    0.1003     0.0010    0.0013   5640.7882    1.0005    ⋯
        β[5]    0.4046    0.1717     0.0017    0.0024   5738.8910    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_2.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.7091    0.9883    1.1984    1.5005    2.4758
           α   -2.3155   -1.9693   -1.7944   -1.6215   -1.3002
        β[1]    0.0144    0.0948    0.1387    0.1827    0.2670
        β[2]    1.0253    1.0958    1.1330    1.1702    1.2433
        β[3]   -0.7837   -0.4725   -0.3196   -0.1699    0.1016
        β[4]    1.5043    1.6309    1.6967    1.7667    1.8967
        β[5]    0.0634    0.2910    0.4062    0.5206    0.7382</code></pre><p><strong>Poisson Regression with Laplace Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_3 = @fitmodel((Num ~ Target + Coop + NCost), sanction,PoissonRegression(),Prior_Laplace())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_3.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    1.0823    0.5395     0.0054    0.0069   5872.8335    0.9999    ⋯
           α   -1.7814    0.2620     0.0026    0.0039   4294.4788    1.0003    ⋯
        β[1]    0.1348    0.0650     0.0006    0.0008   6079.3246    1.0005    ⋯
        β[2]    1.1301    0.0559     0.0006    0.0008   5286.5580    0.9999    ⋯
        β[3]   -0.2920    0.2180     0.0022    0.0025   6993.0113    0.9999    ⋯
        β[4]    1.7007    0.1003     0.0010    0.0011   6536.7210    0.9999    ⋯
        β[5]    0.3912    0.1713     0.0017    0.0022   5883.9841    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_3.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.4566    0.7237    0.9595    1.2933    2.4642
           α   -2.3033   -1.9557   -1.7792   -1.6046   -1.2753
        β[1]    0.0079    0.0912    0.1346    0.1787    0.2634
        β[2]    1.0194    1.0924    1.1297    1.1675    1.2406
        β[3]   -0.7389   -0.4329   -0.2809   -0.1393    0.1095
        β[4]    1.5057    1.6318    1.7001    1.7679    1.8966
        β[5]    0.0544    0.2741    0.3914    0.5073    0.7248</code></pre><p><strong>Poisson Regression with Cauchy Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_4 = @fitmodel((Num ~ Target + Coop + NCost), sanction,PoissonRegression(),Prior_Cauchy())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_4.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.8431    0.4396     0.0044    0.0053   6717.3076    1.0000    ⋯
           α   -1.8054    0.2664     0.0027    0.0041   3746.2526    1.0000    ⋯
        β[1]    0.1387    0.0662     0.0007    0.0009   5517.7524    1.0001    ⋯
        β[2]    1.1335    0.0567     0.0006    0.0008   5064.0582    0.9999    ⋯
        β[3]   -0.2935    0.2202     0.0022    0.0025   7011.9626    1.0000    ⋯
        β[4]    1.7068    0.0997     0.0010    0.0012   7457.7101    1.0000    ⋯
        β[5]    0.3994    0.1700     0.0017    0.0020   5358.2882    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_4.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.2947    0.5437    0.7473    1.0354    1.9601
           α   -2.3319   -1.9825   -1.8040   -1.6236   -1.2908
        β[1]    0.0110    0.0943    0.1380    0.1829    0.2702
        β[2]    1.0240    1.0955    1.1327    1.1714    1.2443
        β[3]   -0.7445   -0.4387   -0.2867   -0.1383    0.1159
        β[4]    1.5128    1.6387    1.7061    1.7741    1.9029
        β[5]    0.0618    0.2876    0.4010    0.5136    0.7320</code></pre><p><strong>Poisson Regression with TDist Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_5 = @fitmodel((Num ~ Target + Coop + NCost), sanction,PoissonRegression(),Prior_TDist())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×20×1 Array{Float64, 3}), Summary Statistics (8 x 8), Quantiles (8 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_5.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    0.9873    0.4110     0.0041    0.0046   6957.8930    1.0000    ⋯
           ν    3.0043    5.6130     0.0561    0.0765   5358.5970    1.0001    ⋯
           α   -1.8086    0.2656     0.0027    0.0037   5218.8150    1.0005    ⋯
        β[1]    0.1408    0.0662     0.0007    0.0008   7020.6232    1.0002    ⋯
        β[2]    1.1343    0.0569     0.0006    0.0007   6744.6596    1.0001    ⋯
        β[3]   -0.3115    0.2225     0.0022    0.0025   8188.3331    0.9999    ⋯
        β[4]    1.7015    0.0999     0.0010    0.0011   8617.1591    1.0001    ⋯
        β[5]    0.4020    0.1696     0.0017    0.0021   6598.9824    1.0001    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_5.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    0.4141    0.6994    0.9178    1.1844    1.9809
           ν    0.5724    1.1495    1.8152    3.1749   12.5313
           α   -2.3392   -1.9818   -1.8097   -1.6301   -1.2844
        β[1]    0.0151    0.0964    0.1406    0.1851    0.2714
        β[2]    1.0217    1.0965    1.1344    1.1726    1.2462
        β[3]   -0.7689   -0.4563   -0.3033   -0.1603    0.1050
        β[4]    1.5067    1.6349    1.7007    1.7682    1.8972
        β[5]    0.0665    0.2894    0.4035    0.5158    0.7293</code></pre><p><strong>Poisson Regression with Uniform Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_6 = @fitmodel((Num ~ Target + Coop + NCost), sanction,PoissonRegression(),Prior_Uniform())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_6.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean        std   naive_se      mcse         ess      rhat   ⋯
      Symbol   Float64    Float64    Float64   Float64     Float64   Float64   ⋯

           λ   31.9778   250.9169     2.5092    4.9465   2490.9386    1.0011   ⋯
           α   -1.9245     0.2659     0.0027    0.0041   3704.7545    0.9999   ⋯
        β[1]    0.1579     0.0660     0.0007    0.0010   4795.5099    0.9999   ⋯
        β[2]    1.1524     0.0558     0.0006    0.0008   4759.2381    0.9999   ⋯
        β[3]   -0.3338     0.2295     0.0023    0.0030   6192.1045    0.9999   ⋯
        β[4]    1.7239     0.1011     0.0010    0.0013   5553.9317    0.9999   ⋯
        β[5]    0.4617     0.1727     0.0017    0.0026   5108.2869    0.9999   ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m3_6.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%      97.5%
      Symbol   Float64   Float64   Float64   Float64    Float64

           λ    2.5472    4.5683    7.7758   16.6635   140.0349
           α   -2.4574   -2.0976   -1.9194   -1.7417    -1.4121
        β[1]    0.0282    0.1132    0.1574    0.2017     0.2897
        β[2]    1.0456    1.1145    1.1516    1.1905     1.2642
        β[3]   -0.8027   -0.4836   -0.3263   -0.1749     0.1026
        β[4]    1.5298    1.6559    1.7236    1.7919     1.9222
        β[5]    0.1133    0.3479    0.4629    0.5798     0.7897</code></pre><h2 id="Example-4:-Negative-Binomial-Regression"><a class="docs-heading-anchor" href="#Example-4:-Negative-Binomial-Regression">Example 4: Negative Binomial Regression</a><a id="Example-4:-Negative-Binomial-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Example-4:-Negative-Binomial-Regression" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; sanction = dataset(&quot;Zelig&quot;, &quot;sanction&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">78×8 DataFrame
 Row │ Mil    Coop   Target  Import  Export  Cost   Num    NCost
     │ Int32  Int32  Int32   Int32   Int32   Int32  Int32  Cat…
─────┼───────────────────────────────────────────────────────────────────
   1 │     1      4       3       1       1      4     15  major loss
   2 │     0      2       3       0       1      3      4  modest loss
   3 │     0      1       3       1       0      2      1  little effect
   4 │     1      1       3       1       1      2      1  little effect
   5 │     0      1       3       1       1      2      1  little effect
   6 │     0      1       3       0       1      2      1  little effect
   7 │     1      2       2       0       1      2      3  little effect
   8 │     0      1       3       0       0      2      3  little effect
  ⋮  │   ⋮      ⋮      ⋮       ⋮       ⋮       ⋮      ⋮          ⋮
  72 │     0      2       2       0       0      1      8  net gain
  73 │     1      3       1       1       1      2     14  little effect
  74 │     0      2       1       0       0      1      2  net gain
  75 │     0      1       3       0       1      2      1  little effect
  76 │     0      4       3       1       0      2     13  little effect
  77 │     0      1       2       0       0      1      1  net gain
  78 │     1      3       1       1       1      2     10  little effect
                                                          63 rows omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sanction</code><code class="nohighlight hljs ansi" style="display:block;">78×8 DataFrame
 Row │ Mil    Coop   Target  Import  Export  Cost   Num    NCost
     │ Int32  Int32  Int32   Int32   Int32   Int32  Int32  Cat…
─────┼───────────────────────────────────────────────────────────────────
   1 │     1      4       3       1       1      4     15  major loss
   2 │     0      2       3       0       1      3      4  modest loss
   3 │     0      1       3       1       0      2      1  little effect
   4 │     1      1       3       1       1      2      1  little effect
   5 │     0      1       3       1       1      2      1  little effect
   6 │     0      1       3       0       1      2      1  little effect
   7 │     1      2       2       0       1      2      3  little effect
   8 │     0      1       3       0       0      2      3  little effect
  ⋮  │   ⋮      ⋮      ⋮       ⋮       ⋮       ⋮      ⋮          ⋮
  72 │     0      2       2       0       0      1      8  net gain
  73 │     1      3       1       1       1      2     14  little effect
  74 │     0      2       1       0       0      1      2  net gain
  75 │     0      1       3       0       1      2      1  little effect
  76 │     0      4       3       1       0      2     13  little effect
  77 │     0      1       2       0       0      1      1  net gain
  78 │     1      3       1       1       1      2     10  little effect
                                                          63 rows omitted</code></pre><p><strong>Negative Binomial Regression - Likelihood method</strong> </p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_1 = @fitmodel((Num ~ Target + Coop + NCost), sanction,NegBinomRegression())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.analysis_Count_NegativeBinom_NIP_Optim(Num ~ Target + Coop + NCost, &quot;CountReg&quot;, &quot;NegativeBinomial&quot;, &quot;NIP&quot;, &quot;LogLink&quot;, &quot;Optimization&quot;, ─────────────────────────────────────────────────────────────────────────────────
                         Coef.  Std. Error      z  Pr(&gt;|z|)  Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────────────
(Intercept)         -1.10939      0.459677  -2.41    0.0158  -2.01034   -0.208444
Target               0.0117398    0.142779   0.08    0.9345  -0.268101   0.291581
Coop                 1.0506       0.111556   9.42    &lt;1e-20   0.831949   1.26924
NCost: major loss   -0.204244     0.508156  -0.40    0.6877  -1.20021    0.791723
NCost: modest loss   1.27142      0.290427   4.38    &lt;1e-04   0.702197   1.84065
NCost: net gain      0.176797     0.254291   0.70    0.4869  -0.321604   0.675197
─────────────────────────────────────────────────────────────────────────────────, [-1.1093939122450307, 0.011739761450928221, 1.0505950803719275, -0.2042442712698661, 1.2714237997560502, 0.17679679808153184], -175.92902143271345, 363.8580428654269, 377.99829582556447)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_1.fit</code><code class="nohighlight hljs ansi" style="display:block;">─────────────────────────────────────────────────────────────────────────────────
                         Coef.  Std. Error      z  Pr(&gt;|z|)  Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────────────
(Intercept)         -1.10939      0.459677  -2.41    0.0158  -2.01034   -0.208444
Target               0.0117398    0.142779   0.08    0.9345  -0.268101   0.291581
Coop                 1.0506       0.111556   9.42    &lt;1e-20   0.831949   1.26924
NCost: major loss   -0.204244     0.508156  -0.40    0.6877  -1.20021    0.791723
NCost: modest loss   1.27142      0.290427   4.38    &lt;1e-04   0.702197   1.84065
NCost: net gain      0.176797     0.254291   0.70    0.4869  -0.321604   0.675197
─────────────────────────────────────────────────────────────────────────────────</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_1.AIC</code><code class="nohighlight hljs ansi" style="display:block;">363.8580428654269</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_1.BIC</code><code class="nohighlight hljs ansi" style="display:block;">377.99829582556447</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_1.lambda_hat</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: type analysis_Count_NegativeBinom_NIP_Optim has no field lambda_hat</code></pre><p><strong>NegativeBinomial Regression with Ridge Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_2 = @fitmodel((Num ~ Target + Coop + NCost), sanction,NegBinomRegression(),Prior_Ridge())</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: DomainError with Dual{ForwardDiff.Tag{Turing.Essential.var&quot;#f#4&quot;{DynamicPPL.TypedVarInfo{NamedTuple{(:λ, :α, :β), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:λ, Setfield.IdentityLens}, Int64}, Vector{Distributions.InverseGamma{Float64}}, Vector{AbstractPPL.VarName{:λ, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:α, Setfield.IdentityLens}, Int64}, Vector{Distributions.Normal{Float64}}, Vector{AbstractPPL.VarName{:α, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:β, Setfield.IdentityLens}, Int64}, Vector{DistributionsAD.TuringScalMvNormal{Vector{Float64}, Float64}}, Vector{AbstractPPL.VarName{:β, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{CRRao.var&quot;#NegBinomReg#16&quot;{Float64}, (:X, :y), (), (), Tuple{Matrix{Float64}, Vector{Int32}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}}(0.0,NaN,NaN,NaN,NaN,NaN,NaN,NaN):
NegativeBinomial: the condition zero(p) &lt; p &lt;= one(p) is not satisfied.</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_2.summaries</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: m4_2 not defined</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_2.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: m4_2 not defined</code></pre><p><strong>NegativeBinomial Regression with Laplace Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_3 = @fitmodel((Num ~ Target + Coop + NCost), sanction,NegBinomRegression(),Prior_Laplace())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_3.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    2.1134    0.4618     0.0046    0.0055   7638.4824    1.0000    ⋯
           α   -1.0016    0.5040     0.0050    0.0088   3647.9901    1.0000    ⋯
        β[1]   -0.0220    0.1589     0.0016    0.0023   5254.4193    1.0001    ⋯
        β[2]    1.0475    0.1310     0.0013    0.0019   4861.2074    0.9999    ⋯
        β[3]   -0.1506    0.5109     0.0051    0.0063   6635.8236    0.9999    ⋯
        β[4]    1.2789    0.3124     0.0031    0.0036   6336.2320    1.0000    ⋯
        β[5]    0.1175    0.2637     0.0026    0.0037   5272.4565    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_3.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    1.3619    1.7892    2.0635    2.3854    3.1767
           α   -2.0087   -1.3393   -0.9942   -0.6544   -0.0229
        β[1]   -0.3353   -0.1270   -0.0217    0.0818    0.2965
        β[2]    0.7954    0.9582    1.0460    1.1333    1.3136
        β[3]   -1.1467   -0.4858   -0.1453    0.1716    0.8887
        β[4]    0.6724    1.0697    1.2756    1.4839    1.9134
        β[5]   -0.3972   -0.0570    0.1141    0.2937    0.6420</code></pre><p><strong>Negative Binomial Regression with Cauchy Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_4 = @fitmodel((Num ~ Target + Coop + NCost), sanction,NegBinomRegression(),Prior_Cauchy())</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_4.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    2.0257    0.4378     0.0044    0.0049   6340.1694    1.0000    ⋯
           α   -1.0476    0.5084     0.0051    0.0081   3792.8174    1.0001    ⋯
        β[1]   -0.0105    0.1591     0.0016    0.0022   5039.3183    0.9999    ⋯
        β[2]    1.0550    0.1309     0.0013    0.0019   5136.1826    1.0007    ⋯
        β[3]   -0.1652    0.5386     0.0054    0.0058   7590.9164    0.9999    ⋯
        β[4]    1.2765    0.3281     0.0033    0.0041   6147.8106    1.0002    ⋯
        β[5]    0.1358    0.2800     0.0028    0.0036   5790.8028    0.9999    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_4.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    1.3089    1.7192    1.9711    2.2815    3.0254
           α   -2.0514   -1.3810   -1.0448   -0.7099   -0.0728
        β[1]   -0.3299   -0.1156   -0.0092    0.0953    0.2980
        β[2]    0.7991    0.9677    1.0526    1.1417    1.3174
        β[3]   -1.1759   -0.5318   -0.1762    0.1772    0.9366
        β[4]    0.6430    1.0597    1.2731    1.4956    1.9217
        β[5]   -0.4180   -0.0497    0.1377    0.3241    0.6798</code></pre><p><strong>Negative Binomial Regression with TDist Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_5 = @fitmodel((Num ~ Target + Coop + NCost), sanction,NegBinomRegression(),Prior_TDist())</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: DomainError with Dual{ForwardDiff.Tag{Turing.Essential.var&quot;#f#4&quot;{DynamicPPL.TypedVarInfo{NamedTuple{(:λ, :ν, :α, :β), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:λ, Setfield.IdentityLens}, Int64}, Vector{Distributions.InverseGamma{Float64}}, Vector{AbstractPPL.VarName{:λ, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:ν, Setfield.IdentityLens}, Int64}, Vector{Distributions.InverseGamma{Float64}}, Vector{AbstractPPL.VarName{:ν, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:α, Setfield.IdentityLens}, Int64}, Vector{Distributions.LocationScale{Float64, Distributions.Continuous, Distributions.TDist{Float64}}}, Vector{AbstractPPL.VarName{:α, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:β, Setfield.IdentityLens}, Int64}, Vector{Distributions.Product{Distributions.Continuous, Distributions.LocationScale{Float64, Distributions.Continuous, Distributions.TDist{Float64}}, FillArrays.Fill{Distributions.LocationScale{Float64, Distributions.Continuous, Distributions.TDist{Float64}}, 1, Tuple{Base.OneTo{Int64}}}}}, Vector{AbstractPPL.VarName{:β, Setfield.IdentityLens}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{CRRao.var&quot;#NegBinomReg#19&quot;{Float64}, (:X, :y), (), (), Tuple{Matrix{Float64}, Vector{Int32}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}}(0.0,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN):
NegativeBinomial: the condition zero(p) &lt; p &lt;= one(p) is not satisfied.</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_5.summaries</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: m4_5 not defined</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_5.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: m4_5 not defined</code></pre><p><strong>Negative Binomial Regression with Uniform Prior</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_6 = @fitmodel((Num ~ Target + Coop + NCost), sanction,NegBinomRegression(),Prior_Uniform(),1.0)</code><code class="nohighlight hljs ansi" style="display:block;">CRRao.MCMC_chain(MCMC chain (10000×19×1 Array{Float64, 3}), Summary Statistics (7 x 8), Quantiles (7 x 6))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_6.summaries</code><code class="nohighlight hljs ansi" style="display:block;">Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ⋯
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ⋯

           λ    2.8005    0.5776     0.0058    0.0057   7625.3807    1.0001    ⋯
           α   -1.1058    0.4671     0.0047    0.0074   3679.6335    1.0000    ⋯
        β[1]   -0.0026    0.1455     0.0015    0.0019   5278.5584    0.9999    ⋯
        β[2]    1.0649    0.1169     0.0012    0.0018   4654.0992    0.9999    ⋯
        β[3]   -0.1894    0.5099     0.0051    0.0056   7573.3084    1.0001    ⋯
        β[4]    1.3044    0.2770     0.0028    0.0033   6779.0708    1.0000    ⋯
        β[5]    0.1605    0.2621     0.0026    0.0034   5641.2622    1.0000    ⋯
                                                                1 column omitted</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; m4_6.quantiles</code><code class="nohighlight hljs ansi" style="display:block;">Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

           λ    1.8764    2.3912    2.7264    3.1309    4.1520
           α   -2.0084   -1.4299   -1.1089   -0.7940   -0.1695
        β[1]   -0.2993   -0.0988    0.0000    0.0954    0.2789
        β[2]    0.8376    0.9876    1.0643    1.1435    1.2977
        β[3]   -1.1631   -0.5346   -0.2010    0.1306    0.8622
        β[4]    0.7588    1.1170    1.3074    1.4959    1.8419
        β[5]   -0.3612   -0.0158    0.1610    0.3391    0.6667</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Wednesday 27 April 2022 06:54">Wednesday 27 April 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
